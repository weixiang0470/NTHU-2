{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d045b25-a92c-404f-96d6-abdff4aff214",
   "metadata": {},
   "source": [
    "## 2-3-1. create a subgraph (1) that consist of a single Linear layer of size MxKxN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d80dc123-cb04-4df5-a10a-d599906a4d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear subgraph (1) created successfully.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "import numpy as np\n",
    "\n",
    "# 定義線性層的形狀參數\n",
    "M, K, N = 1, 9216, 4096  # 假設批量大小為 1，與 AlexNet 第一個 Linear 層對應\n",
    "\n",
    "# 定義名稱\n",
    "input_name = \"input\"  # 輸入名稱\n",
    "weight_name = \"weight\"  # 權重名稱\n",
    "bias_name = \"bias\"  # 偏置名稱（可選）\n",
    "output_name = \"output\"  # 輸出名稱\n",
    "\n",
    "# 創建 Gemm 節點（模擬線性層）\n",
    "gemm_node = helper.make_node(\n",
    "    \"Gemm\",  # 運算子類型\n",
    "    inputs=[input_name, weight_name, bias_name],  # 輸入：數據、權重、偏置\n",
    "    outputs=[output_name],  # 輸出\n",
    "    name=\"linear_layer\",  # 節點名稱\n",
    "    alpha=1.0,  # 縮放因子（默認）\n",
    "    beta=1.0,  # 偏置縮放因子（默認）\n",
    "    transA=0,  # 不轉置 A\n",
    "    transB=1   # 轉置 B\n",
    ")\n",
    "\n",
    "# 創建輸入、權重和偏置的形狀資訊\n",
    "input_info = helper.make_tensor_value_info(input_name, onnx.TensorProto.FLOAT, [M, K])\n",
    "weight_info = helper.make_tensor_value_info(weight_name, onnx.TensorProto.FLOAT, [N, K])\n",
    "bias_info = helper.make_tensor_value_info(bias_name, onnx.TensorProto.FLOAT, [N])\n",
    "output_info = helper.make_tensor_value_info(output_name, onnx.TensorProto.FLOAT, [M, N])\n",
    "\n",
    "# 創建初始值（Initializer）作為示例數據\n",
    "# 隨機生成權重和偏置（用於演示）\n",
    "weight_data = np.random.randn(N, K).astype(np.float32)\n",
    "bias_data = np.random.randn(N).astype(np.float32)\n",
    "\n",
    "weight_initializer = helper.make_tensor(\n",
    "    name=weight_name,\n",
    "    data_type=onnx.TensorProto.FLOAT,\n",
    "    dims=weight_data.shape,\n",
    "    vals=weight_data.flatten().tolist()\n",
    ")\n",
    "\n",
    "bias_initializer = helper.make_tensor(\n",
    "    name=bias_name,\n",
    "    data_type=onnx.TensorProto.FLOAT,\n",
    "    dims=bias_data.shape,\n",
    "    vals=bias_data.flatten().tolist()\n",
    ")\n",
    "\n",
    "# 創建圖（Graph），將 initializers 添加到 graph.initializer\n",
    "graph = helper.make_graph(\n",
    "    [gemm_node],  # 節點列表\n",
    "    \"LinearSubgraph\",  # 圖名稱\n",
    "    inputs=[input_info],  # 輸入\n",
    "    outputs=[output_info]  # 輸出\n",
    ")\n",
    "graph.initializer.extend([weight_initializer, bias_initializer])  # 將 initializers 添加到 graph\n",
    "\n",
    "# 創建模型\n",
    "model = helper.make_model(graph, producer_name=\"LinearSubgraphExample\")\n",
    "\n",
    "# 驗證模型\n",
    "onnx.checker.check_model(model)\n",
    "print(\"Linear subgraph (1) created successfully.\")\n",
    "\n",
    "# 保存子圖為 ONNX 模型（用於測試）\n",
    "onnx.save(model, \"./linear_subgraph.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e92d0500-a0f6-49db-8119-60b555525cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX version: 1.13.1\n",
      "Opset version: 17\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "print(f\"ONNX version: {onnx.__version__}\")\n",
    "model = onnx.load(\"./alexnet.onnx\")\n",
    "print(f\"Opset version: {model.opset_import[0].version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca05fba-bf2e-46d8-b766-ca4b3c368fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph (2) for tiled matrix multiplication created successfully.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 定義名稱\n",
    "input_a_name = \"input_A\"  # 128x128 輸入矩陣 A\n",
    "input_b_name = \"input_B\"  # 128x128 輸入矩陣 B\n",
    "output_c_name = \"output_C\"  # 128x128 輸出矩陣 C\n",
    "\n",
    "# 子塊名稱\n",
    "a_tiles = [\"A00\", \"A01\", \"A10\", \"A11\"]\n",
    "b_tiles = [\"B00\", \"B01\", \"B10\", \"B11\"]\n",
    "c_tiles = [\"C00\", \"C01\", \"C10\", \"C11\"]\n",
    "\n",
    "# 創建 Split 節點（分割 A 和 B，使用 num_outputs 或均勻分割）\n",
    "# 沿 axis=0 分割 A（2 個輸出）\n",
    "split_a_row = helper.make_node(\n",
    "    \"Split\",\n",
    "    inputs=[input_a_name],\n",
    "    outputs=[\"temp_row0\", \"temp_row1\"],\n",
    "    axis=0,  # 沿行分割\n",
    "    # num_outputs=2,  # 僅在較低 Opset 中有效（如 Opset 1-10），在 Opset 17 可能不支援\n",
    "    name=\"split_a_row\"\n",
    ")\n",
    "\n",
    "# 沿 axis=1 分割 A 的每行（每個 2 個輸出）\n",
    "split_a_col0 = helper.make_node(\n",
    "    \"Split\",\n",
    "    inputs=[\"temp_row0\"],\n",
    "    outputs=[a_tiles[0], a_tiles[1]],  # A00, A01\n",
    "    axis=1,  # 沿列分割\n",
    "    # num_outputs=2,\n",
    "    name=\"split_a_col0\"\n",
    ")\n",
    "\n",
    "split_a_col1 = helper.make_node(\n",
    "    \"Split\",\n",
    "    inputs=[\"temp_row1\"],\n",
    "    outputs=[a_tiles[2], a_tiles[3]],  # A10, A11\n",
    "    axis=1,\n",
    "    # num_outputs=2,\n",
    "    name=\"split_a_col1\"\n",
    ")\n",
    "\n",
    "# 沿 axis=0 分割 B（行），沿 axis=1 分割（列）\n",
    "split_b_row = helper.make_node(\n",
    "    \"Split\",\n",
    "    inputs=[input_b_name],\n",
    "    outputs=[\"temp_b_row0\", \"temp_b_row1\"],\n",
    "    axis=0,\n",
    "    # num_outputs=2,\n",
    "    name=\"split_b_row\"\n",
    ")\n",
    "\n",
    "split_b_col0 = helper.make_node(\n",
    "    \"Split\",\n",
    "    inputs=[\"temp_b_row0\"],\n",
    "    outputs=[b_tiles[0], b_tiles[1]],  # B00, B01\n",
    "    axis=1,\n",
    "    # num_outputs=2,\n",
    "    name=\"split_b_col0\"\n",
    ")\n",
    "\n",
    "split_b_col1 = helper.make_node(\n",
    "    \"Split\",\n",
    "    inputs=[\"temp_b_row1\"],\n",
    "    outputs=[b_tiles[2], b_tiles[3]],  # B10, B11\n",
    "    axis=1,\n",
    "    # num_outputs=2,\n",
    "    name=\"split_b_col1\"\n",
    ")\n",
    "\n",
    "# 創建 2DMM（MatMul）和 Sum（Add）節點\n",
    "matmul_nodes = []\n",
    "add_nodes = []\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        # 計算 C_ij 的每個部分\n",
    "        matmul1_output = f\"matmul1_{i}_{j}\"\n",
    "        matmul2_output = f\"matmul2_{i}_{j}\"\n",
    "        matmul_nodes.append(helper.make_node(\n",
    "            \"MatMul\",\n",
    "            inputs=[a_tiles[i * 2], b_tiles[j * 2]],  # A_i0 * B_0j\n",
    "            outputs=[matmul1_output]\n",
    "        ))\n",
    "        matmul_nodes.append(helper.make_node(\n",
    "            \"MatMul\",\n",
    "            inputs=[a_tiles[i * 2 + 1], b_tiles[j * 2 + 1]],  # A_i1 * B_1j\n",
    "            outputs=[matmul2_output]\n",
    "        ))\n",
    "\n",
    "        # 累加（Sum）\n",
    "        sum_output = c_tiles[i * 2 + j]\n",
    "        add_nodes.append(helper.make_node(\n",
    "            \"Add\",\n",
    "            inputs=[matmul1_output, matmul2_output],\n",
    "            outputs=[sum_output]\n",
    "        ))\n",
    "\n",
    "# 創建 Concat 節點（沿 axis=0 和 axis=1 拼接）\n",
    "concat_row0 = helper.make_node(\n",
    "    \"Concat\",\n",
    "    inputs=[c_tiles[0], c_tiles[1]],  # C00, C01\n",
    "    outputs=[\"temp_concat_row0\"],\n",
    "    axis=1,  # 沿列拼接\n",
    "    name=\"concat_row0\"\n",
    ")\n",
    "\n",
    "concat_row1 = helper.make_node(\n",
    "    \"Concat\",\n",
    "    inputs=[c_tiles[2], c_tiles[3]],  # C10, C11\n",
    "    outputs=[\"temp_concat_row1\"],\n",
    "    axis=1,\n",
    "    name=\"concat_row1\"\n",
    ")\n",
    "\n",
    "concat_final = helper.make_node(\n",
    "    \"Concat\",\n",
    "    inputs=[\"temp_concat_row0\", \"temp_concat_row1\"],\n",
    "    outputs=[output_c_name],\n",
    "    axis=0,  # 沿行拼接\n",
    "    name=\"concat_final\"\n",
    ")\n",
    "\n",
    "# 創建圖（Graph）\n",
    "graph = helper.make_graph(\n",
    "    [split_a_row, split_a_col0, split_a_col1, split_b_row, split_b_col0, split_b_col1] + matmul_nodes + add_nodes + [concat_row0, concat_row1, concat_final],\n",
    "    \"TiledMatrixMultiplicationSubgraph\",  # 圖名稱\n",
    "    inputs=[\n",
    "        helper.make_tensor_value_info(input_a_name, onnx.TensorProto.FLOAT, [128, 128]),\n",
    "        helper.make_tensor_value_info(input_b_name, onnx.TensorProto.FLOAT, [128, 128])\n",
    "    ],\n",
    "    outputs=[helper.make_tensor_value_info(output_c_name, onnx.TensorProto.FLOAT, [128, 128])]\n",
    ")\n",
    "\n",
    "# 創建模型，指定 Opset 17\n",
    "model = helper.make_model(graph, producer_name=\"TiledMMExample\", opset_imports=[helper.make_opsetid(\"\", 17)])\n",
    "\n",
    "# 驗證模型\n",
    "onnx.checker.check_model(model)\n",
    "print(\"Subgraph (2) for tiled matrix multiplication created successfully.\")\n",
    "\n",
    "# 保存子圖為 ONNX 模型\n",
    "onnx.save(model, \"./tiled_mm_subgraph.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20af6e-73ca-414f-956a-943a75e8a478",
   "metadata": {},
   "source": [
    "# 2-3-3. replace the Linear layers in the AlexNet with the equivalent subgraphs (2)\n",
    "- saved the transformed model graph for HW2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76860ae-6dc8-4582-a282-f3fd52fc1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# import numpy as np\n",
    "# from onnx import numpy_helper\n",
    "\n",
    "# # 加载 ONNX 模型\n",
    "# model_path = \"./alexnet.onnx\"\n",
    "# model = onnx.load(model_path)\n",
    "\n",
    "# # 提取 Gemm 层的参数\n",
    "# gemm_nodes = [node for node in model.graph.node if node.op_type == \"Gemm\"]\n",
    "# for gemm_node in gemm_nodes:\n",
    "#     print(\"Gemm Node:\", gemm_node.name)\n",
    "#     print(\"Inputs:\", gemm_node.input)\n",
    "#     print(\"Outputs:\", gemm_node.output)\n",
    "#     print(\"Attributes:\", gemm_node.attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e55a03e-6236-4dd1-8907-946624c514f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import shape_inference\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# def get_layer_shapes(model_path, input_shape=None):\n",
    "#     # 加载模型并执行形状推理\n",
    "#     model = onnx.load(model_path)\n",
    "#     model = shape_inference.infer_shapes(model)  # 自动补全形状信息\n",
    "\n",
    "#     # 提取所有张量的形状信息\n",
    "#     tensor_shapes = OrderedDict()\n",
    "\n",
    "#     # 1. 提取模型的输入形状\n",
    "#     for input_tensor in model.graph.input:\n",
    "#         shape = [dim.dim_value if dim.dim_value > 0 else -1  # -1 表示动态维度\n",
    "#                for dim in input_tensor.type.tensor_type.shape.dim]\n",
    "#         tensor_shapes[input_tensor.name] = shape\n",
    "\n",
    "#     # 2. 提取中间层的形状（value_info）\n",
    "#     for value_info in model.graph.value_info:\n",
    "#         shape = [dim.dim_value if dim.dim_value > 0 else -1\n",
    "#                 for dim in value_info.type.tensor_type.shape.dim]\n",
    "#         tensor_shapes[value_info.name] = shape\n",
    "\n",
    "#     # 3. 提取输出形状\n",
    "#     for output_tensor in model.graph.output:\n",
    "#         shape = [dim.dim_value if dim.dim_value > 0 else -1\n",
    "#                 for dim in output_tensor.type.tensor_type.shape.dim]\n",
    "#         tensor_shapes[output_tensor.name] = shape\n",
    "\n",
    "#     # # 4. 遍历所有节点，生成输入/输出形状映射\n",
    "#     # layer_shapes = OrderedDict()\n",
    "\n",
    "#     # # 初始输入形状（如果用户提供了输入形状）\n",
    "#     # if input_shape is not None:\n",
    "#     #     input_name = model.graph.input[0].name\n",
    "#     #     tensor_shapes[input_name] = input_shape\n",
    "\n",
    "#     # for node in model.graph.node:\n",
    "#     #     # 提取当前节点的输入/输出名称\n",
    "#     #     node_inputs = node.input\n",
    "#     #     node_outputs = node.output\n",
    "\n",
    "#     #     # 生成当前层的输入形状\n",
    "#     #     input_shapes = []\n",
    "#     #     for input_name in node_inputs:\n",
    "#     #         if input_name in tensor_shapes:\n",
    "#     #             input_shapes.append(tensor_shapes[input_name])\n",
    "#     #         else:\n",
    "#     #             input_shapes.append(None)  # 未知形状\n",
    "\n",
    "#     #     # 生成当前层的输出形状\n",
    "#     #     output_shapes = []\n",
    "#     #     for output_name in node_outputs:\n",
    "#     #         if output_name in tensor_shapes:\n",
    "#     #             output_shapes.append(tensor_shapes[output_name])\n",
    "#     #         else:\n",
    "#     #             output_shapes.append(None)\n",
    "\n",
    "#     #     # 将结果保存为 {层名称: {inputs: [...], outputs: [...]}}\n",
    "#     #     layer_name = f\"/{node.name}\"  # 用节点名称作为键\n",
    "#     #     layer_shapes[layer_name] = {\n",
    "#     #         \"inputs\": {name: shape for name, shape in zip(node_inputs, input_shapes)},\n",
    "#     #         \"outputs\": {name: shape for name, shape in zip(node_outputs, output_shapes)}\n",
    "#     #     }\n",
    "\n",
    "#     # return layer_shapes, tensor_shapes\n",
    "#     return tensor_shapes\n",
    "\n",
    "# # 使用示例\n",
    "# model_path = \"./alexnet.onnx\"\n",
    "# # layer_shapes, tensor_shapes = get_layer_shapes(model_path, input_shape=[1, 3, 224, 224])\n",
    "# tensor_shapes = get_layer_shapes(model_path, input_shape=[1, 3, 224, 224])\n",
    "\n",
    "# # # 转换为用户要求的格式：{\"层名称/输出名称\": 形状}\n",
    "# # result = {}\n",
    "# # for layer_name, shapes in layer_shapes.items():\n",
    "# #     for output_name, shape in shapes[\"outputs\"].items():\n",
    "# #         key = f\"{layer_name}/{output_name}\"  # 例如 \"/Conv_1/Conv_output_0\"\n",
    "# #         result[key] = shape\n",
    "\n",
    "# # 添加输入形状\n",
    "# # input_name = model.graph.input[0].name\n",
    "# # result[\"actual_input_1\"] = tensor_shapes[input_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4249a79d-d330-41ba-9716-f025b830a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensor in tensor_shapes:\n",
    "#     print(tensor,tensor_shapes[tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c70d165d-0107-4fc9-a4b2-40bdb5faeab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型验证通过！\n",
      "成功創建新的模型！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "from onnx import helper, numpy_helper, shape_inference\n",
    "from onnx import AttributeProto, TensorProto\n",
    "from collections import OrderedDict\n",
    "\n",
    "def split_blocks(total_size, block_size):\n",
    "    if total_size <= 0:\n",
    "        return []\n",
    "    num_blocks = total_size // block_size\n",
    "    remainder = total_size % block_size\n",
    "    return [block_size] * num_blocks + ([remainder] if remainder != 0 else [])\n",
    "\n",
    "def validate_node_connections(model):\n",
    "    existing_outputs = set()\n",
    "    existing_initializers = set(init.name for init in model.graph.initializer)\n",
    "    existing_inputs = set(input.name for input in model.graph.input)\n",
    "    \n",
    "    # 收集所有節點的輸出\n",
    "    for node in model.graph.node:\n",
    "        for output in node.output:\n",
    "            existing_outputs.add(output)\n",
    "    \n",
    "    # 驗證每個輸入是否有效\n",
    "    for node in model.graph.node:\n",
    "        for input_name in node.input:\n",
    "            if (input_name not in existing_outputs and \n",
    "                input_name not in existing_initializers and \n",
    "                input_name not in existing_inputs):\n",
    "                raise ValueError(f\"未定義的輸入: {input_name} 在節點 {node.name}\")\n",
    "\n",
    "def replace_gemm_with_blocks(model, max_block_size=1024):\n",
    "    model = shape_inference.infer_shapes(model)\n",
    "    value_info = {info.name: info for info in model.graph.value_info}\n",
    "    initializers = {init.name: init for init in model.graph.initializer}\n",
    "    \n",
    "    new_nodes = []\n",
    "    new_initializers = list(model.graph.initializer)  # 保留所有原始初始器\n",
    "    name_counter = 0\n",
    "    \n",
    "    for node in model.graph.node:\n",
    "        if node.op_type != 'Gemm':\n",
    "            new_nodes.append(node)\n",
    "            continue\n",
    "            \n",
    "        # 提取 Gemm 參數\n",
    "        transA, transB, alpha, beta = 0, 0, 1.0, 1.0\n",
    "        for attr in node.attribute:\n",
    "            if attr.name == 'transA': transA = attr.i\n",
    "            if attr.name == 'transB': transB = attr.i\n",
    "            if attr.name == 'alpha': alpha = attr.f\n",
    "            if attr.name == 'beta': beta = attr.f\n",
    "        \n",
    "        A_input = node.input[0]\n",
    "        B_input = node.input[1]\n",
    "        C_input = node.input[2] if len(node.input) > 2 else None\n",
    "        \n",
    "        # 處理權重矩陣 B\n",
    "        B = numpy_helper.to_array(initializers[B_input]).copy()\n",
    "        if transB:\n",
    "            B = B.T\n",
    "        if alpha != 1.0:\n",
    "            B *= alpha\n",
    "        \n",
    "        # 獲取實際運算維度\n",
    "        A_shape = [d.dim_value for d in value_info[A_input].type.tensor_type.shape.dim]\n",
    "        if transA:\n",
    "            M = A_shape[0]  # 轉置後的行數\n",
    "        else:\n",
    "            M = A_shape[1]\n",
    "        N = B.shape[1]\n",
    "        \n",
    "        # 動態分塊\n",
    "        block_sizes_M = split_blocks(M, max_block_size)\n",
    "        block_sizes_N = split_blocks(N, max_block_size)\n",
    "        \n",
    "        # ================= 構建分塊權重 =================\n",
    "        B_blocks = []\n",
    "        for i, block_m in enumerate(block_sizes_M):\n",
    "            row_start = sum(block_sizes_M[:i])\n",
    "            row_end = row_start + block_m\n",
    "            for j, block_n in enumerate(block_sizes_N):\n",
    "                col_start = sum(block_sizes_N[:j])\n",
    "                col_end = col_start + block_n\n",
    "                block = B[row_start:row_end, col_start:col_end]\n",
    "                \n",
    "                # 生成唯一名稱\n",
    "                block_name = f\"{B_input}_block_{i}_{j}_{name_counter}\"\n",
    "                name_counter += 1\n",
    "                B_blocks.append((i, j, block_name))\n",
    "                new_initializers.append(\n",
    "                    numpy_helper.from_array(block.astype(np.float32), name=block_name)\n",
    "                )\n",
    "        \n",
    "        # ================= 重構計算圖 =================\n",
    "        # 步驟1：拆分輸入A\n",
    "        split_axis = 0 if transA else 1  # 根據transA選擇拆分軸\n",
    "        split_outputs = [f\"{node.name}_A_block_{i}_{name_counter}\" for i in range(len(block_sizes_M))]\n",
    "        # 創建 split 參數的 initializer\n",
    "        split_tensor_name = f\"{node.name}_split_sizes_{name_counter}\"\n",
    "        split_initializer = numpy_helper.from_array(\n",
    "            np.array(block_sizes_M, dtype=np.int64),\n",
    "            name=split_tensor_name\n",
    "        )\n",
    "        new_initializers.append(split_initializer)\n",
    "        \n",
    "        split_node = helper.make_node(\n",
    "            \"Split\",\n",
    "            inputs=[A_input, split_tensor_name],  # ONNX opset>=13 使用輸入參數\n",
    "            outputs=split_outputs,\n",
    "            axis=split_axis\n",
    "        )\n",
    "        new_nodes.append(split_node)\n",
    "        name_counter += 1\n",
    "        \n",
    "        # 步驟2：矩陣乘法分塊\n",
    "        matmul_outputs = []\n",
    "        for (i, j, B_block_name) in B_blocks:\n",
    "            A_block_name = split_outputs[i]\n",
    "            \n",
    "            # 處理transA\n",
    "            if transA:\n",
    "                transpose_node = helper.make_node(\n",
    "                    \"Transpose\",\n",
    "                    inputs=[A_block_name],\n",
    "                    outputs=[f\"{A_block_name}_transposed\"],\n",
    "                    perm=[1, 0]\n",
    "                )\n",
    "                new_nodes.append(transpose_node)\n",
    "                A_block_name = f\"{A_block_name}_transposed\"\n",
    "            \n",
    "            matmul_name = f\"{node.name}_MatMul_{i}_{j}_{name_counter}\"\n",
    "            name_counter += 1\n",
    "            matmul_output = f\"{matmul_name}_output\"\n",
    "            matmul_node = helper.make_node(\n",
    "                \"MatMul\",\n",
    "                inputs=[A_block_name, B_block_name],\n",
    "                outputs=[matmul_output]\n",
    "            )\n",
    "            new_nodes.append(matmul_node)\n",
    "            matmul_outputs.append((j, matmul_output))\n",
    "        \n",
    "        # 步驟3：按列求和\n",
    "        sum_outputs = []\n",
    "        for j in range(len(block_sizes_N)):\n",
    "            sum_inputs = [out for idx, out in matmul_outputs if idx == j]\n",
    "            if not sum_inputs:\n",
    "                continue\n",
    "            \n",
    "            if len(sum_inputs) == 1:\n",
    "                sum_output = sum_inputs[0]\n",
    "            else:\n",
    "                sum_name = f\"{node.name}_Sum_{j}_{name_counter}\"\n",
    "                name_counter += 1\n",
    "                sum_node = helper.make_node(\n",
    "                    \"Sum\",\n",
    "                    inputs=sum_inputs,\n",
    "                    outputs=[sum_name]\n",
    "                )\n",
    "                new_nodes.append(sum_node)\n",
    "                sum_output = sum_name\n",
    "            sum_outputs.append(sum_output)\n",
    "        \n",
    "        # 步驟4：拼接結果\n",
    "        concat_node = helper.make_node(\n",
    "            \"Concat\",\n",
    "            inputs=sum_outputs,\n",
    "            outputs=[f\"{node.name}_Concat_{name_counter}\"],\n",
    "            axis=1\n",
    "        )\n",
    "        name_counter += 1\n",
    "        new_nodes.append(concat_node)\n",
    "        final_output = f\"{node.name}_Concat_{name_counter-1}\"\n",
    "        \n",
    "        # 步驟5：處理偏置\n",
    "        if C_input is not None:\n",
    "            if beta != 1.0:\n",
    "                # 添加beta縮放\n",
    "                beta_array = np.array([beta], dtype=np.float32)\n",
    "                beta_initializer = numpy_helper.from_array(beta_array, name=f\"{node.name}_beta_{name_counter}\")\n",
    "                new_initializers.append(beta_initializer)\n",
    "                beta_node = helper.make_node(\n",
    "                    \"Mul\",\n",
    "                    inputs=[C_input, beta_initializer.name],\n",
    "                    outputs=[f\"{node.name}_ScaledBias_{name_counter}\"]\n",
    "                )\n",
    "                new_nodes.append(beta_node)\n",
    "                C_input = f\"{node.name}_ScaledBias_{name_counter}\"\n",
    "                name_counter += 1\n",
    "            \n",
    "            add_node = helper.make_node(\n",
    "                \"Add\",\n",
    "                inputs=[final_output, C_input],\n",
    "                outputs=node.output\n",
    "            )\n",
    "            new_nodes.append(add_node)\n",
    "        else:\n",
    "            identity_node = helper.make_node(\n",
    "                \"Identity\",\n",
    "                inputs=[final_output],\n",
    "                outputs=node.output\n",
    "            )\n",
    "            new_nodes.append(identity_node)\n",
    "    \n",
    "    # ================= 更新模型 =================\n",
    "    model.graph.ClearField('node')\n",
    "    model.graph.node.extend(new_nodes)\n",
    "    \n",
    "    model.graph.ClearField('initializer')\n",
    "    model.graph.initializer.extend(new_initializers)\n",
    "    \n",
    "    # 形狀推斷與驗證\n",
    "    model = shape_inference.infer_shapes(model)\n",
    "    validate_node_connections(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def validate_model_transformation(orig_model_path, modified_model_path):\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    # 加載原始模型\n",
    "    orig_model = onnx.load(orig_model_path)\n",
    "    orig_input_name = orig_model.graph.input[0].name\n",
    "    \n",
    "    # 生成測試數據\n",
    "    np.random.seed(0)\n",
    "    input_shape = [dim.dim_value for dim in orig_model.graph.input[0].type.tensor_type.shape.dim]\n",
    "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "    \n",
    "    # 原始模型推理\n",
    "    sess_orig = ort.InferenceSession(orig_model_path)\n",
    "    output_orig = sess_orig.run(None, {orig_input_name: input_data})[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sess_mod = ort.InferenceSession(modified_model_path)\n",
    "    mod_input_name = sess_mod.get_inputs()[0].name\n",
    "    output_mod = sess_mod.run(None, {mod_input_name: input_data})[0]\n",
    "    \n",
    "    # 數值驗證\n",
    "    try:\n",
    "        np.testing.assert_allclose(output_orig, output_mod, atol=1e-5)\n",
    "        print(\"✅ 驗證成功！輸出一致\")\n",
    "    except AssertionError as e:\n",
    "        max_diff = np.max(np.abs(output_orig - output_mod))\n",
    "        print(f\"⚠️ 驗證失敗！最大絕對誤差: {max_diff:.2e}\")\n",
    "        # raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 使用範例\n",
    "    orig_model_path = \"./alexnet.onnx\"\n",
    "    modified_model_path = \"./alexnet_modified.onnx\"\n",
    "    # 修改模型推理\n",
    "    orig_model = onnx.load(orig_model_path)\n",
    "    modified_model = replace_gemm_with_blocks(orig_model)\n",
    "    modified_model = shape_inference.infer_shapes(modified_model)\n",
    "\n",
    "    # 验证修改后的模型\n",
    "    onnx.checker.check_model(modified_model)\n",
    "    print(\"模型验证通过！\")\n",
    "\n",
    "    onnx.save(modified_model, modified_model_path)\n",
    "    print(\"成功創建新的模型！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f74452-c47f-41bf-91ad-8c6608b77725",
   "metadata": {},
   "source": [
    "# 2-3-4. Correctness Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe86e21b-1942-4657-9d31-783ee3a0c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-03-08 09:09:20.946614042 [W:onnxruntime:, graph.cc:4198 CleanUnusedInitializersAndNodeArgs] Removing initializer 'learned_12'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-08 09:09:20.947065292 [W:onnxruntime:, graph.cc:4198 CleanUnusedInitializersAndNodeArgs] Removing initializer 'learned_14'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-08 09:09:20.947077625 [W:onnxruntime:, graph.cc:4198 CleanUnusedInitializersAndNodeArgs] Removing initializer 'learned_10'. It is not used by any node and should be removed from the model.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始驗證 100 個隨機樣本...\n",
      "已處理 10/100 個樣本，耗時 6.41 秒， 目前成功數為 10\n",
      "已處理 20/100 個樣本，耗時 12.54 秒， 目前成功數為 20\n",
      "已處理 30/100 個樣本，耗時 18.68 秒， 目前成功數為 30\n",
      "已處理 40/100 個樣本，耗時 26.76 秒， 目前成功數為 40\n",
      "已處理 50/100 個樣本，耗時 35.10 秒， 目前成功數為 50\n",
      "已處理 60/100 個樣本，耗時 43.37 秒， 目前成功數為 60\n",
      "已處理 70/100 個樣本，耗時 51.50 秒， 目前成功數為 70\n",
      "已處理 80/100 個樣本，耗時 59.75 秒， 目前成功數為 80\n",
      "已處理 90/100 個樣本，耗時 67.74 秒， 目前成功數為 90\n",
      "已處理 100/100 個樣本，耗時 76.06 秒， 目前成功數為 100\n",
      "\n",
      "驗證結果:\n",
      "總樣本數: 100\n",
      "通過樣本數: 100\n",
      "失敗樣本數: 0\n",
      "總耗時: 76.06 秒\n",
      "✅ 所有樣本驗證成功！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "\n",
    "def validate_models(original_model_path, transformed_model_path, num_samples=100):\n",
    "    # 初始化推理會話\n",
    "    orig_sess = ort.InferenceSession(original_model_path)\n",
    "    trans_sess = ort.InferenceSession(transformed_model_path)\n",
    "\n",
    "    # 獲取模型輸入/輸出信息\n",
    "    orig_input_name = orig_sess.get_inputs()[0].name\n",
    "    trans_input_name = trans_sess.get_inputs()[0].name\n",
    "    output_name = orig_sess.get_outputs()[0].name  # 假設單一輸出\n",
    "\n",
    "    # 獲取輸入形狀 (支持動態 batch_size)\n",
    "    input_shape = list(orig_sess.get_inputs()[0].shape)\n",
    "    input_shape = [dim if dim > 0 else 1 for dim in input_shape]  # 處理動態維度\n",
    "\n",
    "    # 初始化驗證結果\n",
    "    all_passed = True\n",
    "    failed_samples = []\n",
    "\n",
    "    # 執行批量驗證\n",
    "    print(f\"開始驗證 {num_samples} 個隨機樣本...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 生成隨機輸入數據\n",
    "        np.random.seed(i)  # 為可重現性設置種子\n",
    "        input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "        \n",
    "        # 原始模型推理\n",
    "        orig_output = orig_sess.run([output_name], {orig_input_name: input_data})[0]\n",
    "        \n",
    "        # 轉換模型推理\n",
    "        trans_output = trans_sess.run([output_name], {trans_input_name: input_data})[0]\n",
    "        \n",
    "        # 比較結果\n",
    "        if not np.allclose(orig_output, trans_output, atol=1e-5):\n",
    "            max_diff = np.max(np.abs(orig_output - trans_output))\n",
    "            print(f\"樣本 {i} 驗證失敗，最大差異: {max_diff:.2e}\")\n",
    "            all_passed = False\n",
    "            failed_samples.append(i)\n",
    "            \n",
    "        # 進度顯示\n",
    "        if (i+1) % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"已處理 {i+1}/{num_samples} 個樣本，耗時 {elapsed:.2f} 秒， 目前成功數為 {i+1 - len(failed_samples)}\")\n",
    "\n",
    "    # 最終報告\n",
    "    total_time = time.time() - start_time\n",
    "    print(\"\\n驗證結果:\")\n",
    "    print(f\"總樣本數: {num_samples}\")\n",
    "    print(f\"通過樣本數: {num_samples - len(failed_samples)}\")\n",
    "    print(f\"失敗樣本數: {len(failed_samples)}\")\n",
    "    print(f\"總耗時: {total_time:.2f} 秒\")\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"✅ 所有樣本驗證成功！\")\n",
    "    else:\n",
    "        print(f\"❌ 發現 {len(failed_samples)} 個失敗樣本:\")\n",
    "        print(f\"失敗樣本索引: {failed_samples}\")\n",
    "        raise ValueError(\"模型輸出不匹配\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 模型路徑配置\n",
    "    original_model = \"./alexnet.onnx\"\n",
    "    transformed_model = \"./alexnet_modified.onnx\"\n",
    "\n",
    "    # 執行驗證\n",
    "    validate_models(original_model, transformed_model, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b38ac-0547-41e3-8b79-6a299124c9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31027e55-d9f8-4c14-a0b8-ff978ac80699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
