{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21499573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt #1\n",
      "Generated description: Powerful eco-ad, dolphin, urging action\n",
      "With parameters: {'style': 'illustration', 'creativity': np.float64(0.6000000000000001)}\n",
      "show image\n",
      "I will generate an image based on a concept that embodies the essence of the provided options, focusing on a visually striking and emotionally resonant scene that highlights the beauty and vulnerability of dolphins and the urgent need for ocean conservation. The image will feature a pod of dolphins swimming in clear turquoise waters, with sunlight filtering through the surface. One dolphin will be prominently featured, looking directly towards the viewer with an intelligent and perhaps slightly melancholic expression, conveying a silent plea. Subtle elements of human impact, such as a faint piece of plastic drifting nearby (but not overwhelming), will hint at the threats they face without detracting from the natural beauty. The overall tone will be both breathtaking and subtly urgent, aiming to evoke a sense of responsibility and inspire action for ocean protection.\n",
      "\n",
      "Thank you for your feedback! We've found a satisfactory result.\n",
      "\n",
      "Best result:\n",
      "I will generate an image based on a concept that embodies the essence of the provided options, focusing on a visually striking and emotionally resonant scene that highlights the beauty and vulnerability of dolphins and the urgent need for ocean conservation. The image will feature a pod of dolphins swimming in clear turquoise waters, with sunlight filtering through the surface. One dolphin will be prominently featured, looking directly towards the viewer with an intelligent and perhaps slightly melancholic expression, conveying a silent plea. Subtle elements of human impact, such as a faint piece of plastic drifting nearby (but not overwhelming), will hint at the threats they face without detracting from the natural beauty. The overall tone will be both breathtaking and subtly urgent, aiming to evoke a sense of responsibility and inspire action for ocean protection.\n",
      "\n",
      "Score: 5.0\n",
      "\n",
      "All feedback:\n",
      "Attempt 1 - Score: 5.0, Comment: add text\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "# import google.generativeai as genai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from typing import List, Dict, Tuple\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "client = genai.Client(api_key='AIzaSyC7quYU5Pxd4yesROoiRG0E9SH1itodY5I')\n",
    "\n",
    "def display_image(image_data):\n",
    "    \"\"\"Display an image from binary data\"\"\"\n",
    "    for part in image_data.candidates[0].content.parts:\n",
    "        if part.text is not None:\n",
    "            print(part.text)\n",
    "        elif part.inline_data is not None:\n",
    "            img = Image.open(BytesIO((part.inline_data.data)))\n",
    "            img.show()  # This opens the image using your system's default viewer\n",
    "\n",
    "# Image generation API (example using a mock API)\n",
    "def generate_image(prompt: str, style: str = \"photographic\", creativity: float = 0.5) -> str:\n",
    "    response = client.models.generate_content(\n",
    "        model = \"gemini-2.0-flash-preview-image-generation\",\n",
    "        contents=(prompt,style),\n",
    "        config = types.GenerateContentConfig(\n",
    "            response_modalities=['TEXT','IMAGE']\n",
    "        )\n",
    "    )\n",
    "    # print(\"show image\")\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        if part.text is not None:\n",
    "            print(part.text)\n",
    "        elif part.inline_data is not None:\n",
    "            img = Image.open(BytesIO((part.inline_data.data)))\n",
    "            img.show() \n",
    "        # print(\"inline_data = \",part.inline_data)\n",
    "\n",
    "    return response\n",
    "# Reinforcement learning model for ad optimization\n",
    "class AdOptimizer:\n",
    "    def __init__(self):\n",
    "        # Initialize prompt modification strategies\n",
    "        self.prompt_modifications = [\n",
    "            lambda p: f\"Eco-friendly advertisement image, {p}, with a nature background\",\n",
    "            lambda p: f\"Minimalist style, {p}, with green environmental themes\",\n",
    "            lambda p: f\"Powerful eco-ad, {p}, urging action\",\n",
    "            lambda p: f\"Creative green ad, {p}, with sustainability themes\"\n",
    "        ]\n",
    "        \n",
    "        # Initialize style and creativity options\n",
    "        self.style_options = [\"photographic\", \"illustration\", \"3d-rendering\", \"watercolor\"]\n",
    "        self.creativity_options = np.linspace(0.3, 0.9, 5)\n",
    "        \n",
    "        # Initialize value estimates for each action\n",
    "        self.action_values = np.zeros(len(self.prompt_modifications) * len(self.style_options) * len(self.creativity_options))\n",
    "        self.action_counts = np.zeros_like(self.action_values)\n",
    "        \n",
    "    def select_action(self, prompt: str) -> Tuple[str, Dict, int]:\n",
    "        \"\"\"Select an action based on the current strategy\"\"\"\n",
    "        epsilon = 0.2  # Exploration probability\n",
    "        if np.random.random() < epsilon:\n",
    "            # Explore: randomly pick an action\n",
    "            mod_idx = np.random.randint(len(self.prompt_modifications))\n",
    "            style_idx = np.random.randint(len(self.style_options))\n",
    "            creativity_idx = np.random.randint(len(self.creativity_options))\n",
    "        else:\n",
    "            # Exploit: pick the best known action\n",
    "            best_idx = np.argmax(self.action_values)\n",
    "            mod_idx = best_idx % len(self.prompt_modifications)\n",
    "            remaining = best_idx // len(self.prompt_modifications)\n",
    "            style_idx = remaining % len(self.style_options)\n",
    "            creativity_idx = remaining // len(self.style_options)\n",
    "        \n",
    "        # Apply selected modifications\n",
    "        new_prompt = self.prompt_modifications[mod_idx](prompt)\n",
    "        params = {\n",
    "            \"style\": self.style_options[style_idx],\n",
    "            \"creativity\": self.creativity_options[creativity_idx]\n",
    "        }\n",
    "        \n",
    "        action_id = mod_idx + style_idx * len(self.prompt_modifications) + \\\n",
    "                   creativity_idx * len(self.prompt_modifications) * len(self.style_options)\n",
    "        \n",
    "        return new_prompt, params, action_id\n",
    "    \n",
    "    def update_model(self, action_id: int, reward: float):\n",
    "        \"\"\"Update model based on user feedback\"\"\"\n",
    "        self.action_counts[action_id] += 1\n",
    "        n = self.action_counts[action_id]\n",
    "        \n",
    "        # Incremental update of value estimate\n",
    "        current_value = self.action_values[action_id]\n",
    "        self.action_values[action_id] = current_value + (reward - current_value) / n\n",
    "\n",
    "# Main program\n",
    "def main():\n",
    "    optimizer = AdOptimizer()\n",
    "    \n",
    "    # Get user input\n",
    "    user_prompt = input(\"Enter your desired eco-ad theme (e.g., Reduce plastic usage): \")\n",
    "    \n",
    "    iteration = 0\n",
    "    max_iterations = 5\n",
    "    best_image = None\n",
    "    best_score = 0\n",
    "    feedback_log = []\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        # Generate candidate advertisement\n",
    "        modified_prompt, params, action_id = optimizer.select_action(user_prompt)\n",
    "        \n",
    "        print(f\"\\nAttempt #{iteration + 1}\")\n",
    "        print(f\"Generated description: {modified_prompt}\")\n",
    "        print(f\"With parameters: {params}\")\n",
    "        \n",
    "        try:\n",
    "            # Optimize the prompt using Gemini\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[f\"Optimize the following eco-ad description to make it more attractive and accurate: {modified_prompt}\"]\n",
    "            )\n",
    "            # response = model.generate_content()\n",
    "            final_prompt =\"Please generate image.\"+ response.text\n",
    "            \n",
    "            # Generate image\n",
    "            image_data = generate_image(final_prompt, **params)\n",
    "            \n",
    "            # Display image\n",
    "            # display_image(image_data)\n",
    "            \n",
    "            # Collect user feedback\n",
    "            score = float(input(\"Rate this image (1-5, with 5 being most satisfied): \"))\n",
    "            comment = input(\"Provide a comment for this image (optional): \")\n",
    "            \n",
    "            # Update model\n",
    "            optimizer.update_model(action_id, score)\n",
    "            \n",
    "            # Log feedback\n",
    "            feedback_log.append({\n",
    "                'iteration': iteration + 1,\n",
    "                'score': score,\n",
    "                'comment': comment,\n",
    "                'image_data': image_data\n",
    "            })\n",
    "            \n",
    "            # Update best result\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_image = image_data\n",
    "            \n",
    "            if score >= 4:\n",
    "                print(\"Thank you for your feedback! We've found a satisfactory result.\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during image generation: {e}\")\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    # Show best result\n",
    "    if best_image:\n",
    "        print(\"\\nBest result:\")\n",
    "        display_image(best_image)\n",
    "        print(f\"Score: {best_score}\")\n",
    "    \n",
    "    # Show all feedback\n",
    "    print(\"\\nAll feedback:\")\n",
    "    for feedback in feedback_log:\n",
    "        print(f\"Attempt {feedback['iteration']} - Score: {feedback['score']}, Comment: {feedback['comment']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3138d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will add a fluffy, light brown llama standing comfortably next to you in the image.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "image = PIL.Image.open('test.png')\n",
    "image.show()\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyC7quYU5Pxd4yesROoiRG0E9SH1itodY5I\")\n",
    "\n",
    "text_input = ('Hi, This is a picture of me.'\n",
    "            'Can you add a llama next to me?',)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "    contents=[text_input, image],\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['TEXT', 'IMAGE']\n",
    "    )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(part.text)\n",
    "  elif part.inline_data is not None:\n",
    "    image = Image.open(BytesIO(part.inline_data.data))\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0306ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A detailed scene of futuristic eco-village.\n",
      "Include the following sustainability elements:\n",
      "- wind turbines and solar panels\n",
      "- rooftop gardens and vertical farms\n",
      "- clean rivers, forests, and ocean coastlines\n",
      "- eco-friendly buildings made from recycled materials\n",
      "Visual style: flat vector illustration with soft gradients.\n",
      "Additional instructions: Use warm morning light and show people interacting peacefully.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_gemini_image_prompt_with_sustainability(\n",
    "    theme: str,\n",
    "    style: str,\n",
    "    additional_details: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a clean, Gemini-friendly English prompt for image generation, with sustainability elements.\n",
    "\n",
    "    :param theme:              Main subject or concept (e.g., 'urban garden').\n",
    "    :param style:              Desired visual art style (e.g., 'flat vector', 'digital painting').\n",
    "    :param additional_details: Optional extra details to be included in the prompt.\n",
    "    :return:                   A Gemini-optimized prompt string.\n",
    "    \"\"\"\n",
    "\n",
    "    sustainability_elements = [\n",
    "        \"wind turbines and solar panels\",\n",
    "        \"rooftop gardens and vertical farms\",\n",
    "        \"recycling bins and composting stations\",\n",
    "        \"bike lanes and electric buses\",\n",
    "        \"people planting trees and harvesting vegetables\",\n",
    "        \"children learning about nature outdoors\",\n",
    "        \"animals living peacefully in city spaces\",\n",
    "        \"eco-friendly buildings made from recycled materials\",\n",
    "        \"clean rivers, forests, and ocean coastlines\",\n",
    "        \"green rooftops and rainwater collection systems\"\n",
    "    ]\n",
    "\n",
    "    # 隨機選擇 3-5 個元素\n",
    "    selected = random.sample(sustainability_elements, k=random.randint(3, 5))\n",
    "\n",
    "    # 主題與元素合併為敘述\n",
    "    prompt_lines = [\n",
    "        f\"A detailed scene of {theme}.\",\n",
    "        \"Include the following sustainability elements:\",\n",
    "        *[f\"- {element}\" for element in selected],\n",
    "        f\"Visual style: {style}.\",\n",
    "    ]\n",
    "\n",
    "    if additional_details:\n",
    "        prompt_lines.append(f\"Additional instructions: {additional_details}\")\n",
    "\n",
    "    # 合併為完整 prompt\n",
    "    return \"\\n\".join(prompt_lines)\n",
    "\n",
    "\n",
    "# ✅ 測試範例\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = generate_gemini_image_prompt_with_sustainability(\n",
    "        theme=\"futuristic eco-village\",\n",
    "        style=\"flat vector illustration with soft gradients\",\n",
    "        additional_details=\"Use warm morning light and show people interacting peacefully.\"\n",
    "    )\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa18555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A detailed scene of Ocean. (weight=7.0)\n",
      "Include the following visual elements with weight = 2.0:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- eco-friendly market stalls made of reclaimed wood\n",
      "- recycling bins and composting stations\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows. (weight 4.0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "def generate_gemini_sustainable_prompt(\n",
    "    theme: str,\n",
    "    style: str,\n",
    "    user_elements: List[str],\n",
    "    additional_details: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a Gemini-optimized image generation prompt by combining user input with automatic sustainability elements.\n",
    "\n",
    "    :param theme:            Main subject or concept (e.g., 'community event').\n",
    "    :param style:            Desired visual art style (e.g., 'digital painting').\n",
    "    :param user_elements:    User-specified elements to include in the scene (not necessarily sustainable).\n",
    "    :param additional_details: Optional extra instructions.\n",
    "    :return:                 A complete prompt string suitable for Gemini image generation.\n",
    "    \"\"\"\n",
    "\n",
    "    sustainability_elements_pool = [\n",
    "        \"solar panels on rooftops\",\n",
    "        \"wind turbines in the background\",\n",
    "        \"recycling bins and composting stations\",\n",
    "        \"people using reusable containers and utensils\",\n",
    "        \"urban gardens and community green spaces\",\n",
    "        \"electric bikes or scooters\",\n",
    "        \"rainwater collection barrels\",\n",
    "        \"eco-friendly market stalls made of reclaimed wood\",\n",
    "        \"children learning about nature\",\n",
    "        \"clean rivers and green walkways\"\n",
    "    ]\n",
    "    sustainability_elements = [\n",
    "        \"wind turbines and solar panels\",\n",
    "        \"rooftop gardens and vertical farms\",\n",
    "        \"recycling bins and composting stations\",\n",
    "        \"bike lanes and electric buses\",\n",
    "        \"people planting trees and harvesting vegetables\",\n",
    "        \"children learning about nature outdoors\",\n",
    "        \"animals living peacefully in city spaces\",\n",
    "        \"eco-friendly buildings made from recycled materials\",\n",
    "        \"clean rivers, forests, and ocean coastlines\",\n",
    "        \"green rooftops and rainwater collection systems\"\n",
    "    ]\n",
    "\n",
    "    selected_sustainability = random.sample(sustainability_elements_pool, k=random.randint(2, 4))\n",
    "\n",
    "    prompt_lines = [\n",
    "        f\"A detailed scene of {theme}. (weight=7.0)\",\n",
    "        \"Include the following visual elements with weight = 2.0:\",\n",
    "        *[f\"- {element}\" for element in user_elements],\n",
    "        *[f\"- {s_element}\" for s_element in selected_sustainability],\n",
    "        f\"Visual style: {style}.\"\n",
    "    ]\n",
    "\n",
    "    if additional_details:\n",
    "        prompt_lines.append(f\"Additional instructions: {additional_details} (weight 4.0)\")\n",
    "\n",
    "    return \"\\n\".join(prompt_lines)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = generate_gemini_sustainable_prompt(\n",
    "        theme=\"Ocean\",\n",
    "        style=\"colorful flat illustration\",\n",
    "        user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"],\n",
    "        additional_details=\"Use a warm sunset palette with soft shadows.\"\n",
    "    )\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb7724",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d6fa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt #1\n",
      "Generated description: Minimalist style, 草泥馬, with green environmental themes\n",
      "With parameters: {'style': 'photographic', 'creativity': np.float64(0.3)}\n",
      "Error during image generation: could not convert string to float: ''\n",
      "\n",
      "Attempt #2\n",
      "Generated description: Minimalist style, 草泥馬, with green environmental themes\n",
      "With parameters: {'style': 'photographic', 'creativity': np.float64(0.3)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 159\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Comment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 113\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    109\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.0-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m     contents\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimize the following eco-ad description to make it more attractive and accurate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodified_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m final_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease generate image. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m--> 113\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m generated_img \u001b[38;5;241m=\u001b[39m extract_image_from_response(image_data)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generated_img:\n",
      "Cell \u001b[0;32mIn[5], line 38\u001b[0m, in \u001b[0;36mgenerate_image\u001b[0;34m(prompt, style, creativity)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_image\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, style: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphotographic\u001b[39m\u001b[38;5;124m\"\u001b[39m, creativity: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-2.0-flash-preview-image-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerateContentConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_modalities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEXT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIMAGE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/models.py:5049\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5047\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5048\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5049\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5050\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m   5051\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5052\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   5053\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/models.py:4025\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4022\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   4023\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4025\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4026\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[1;32m   4030\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(\n\u001b[1;32m   4031\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client, response_dict\n\u001b[1;32m   4032\u001b[0m   )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/_api_client.py:751\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    743\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    747\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[BaseResponse, Any]:\n\u001b[1;32m    748\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m    749\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m    750\u001b[0m   )\n\u001b[0;32m--> 751\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m   json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson\n\u001b[1;32m    753\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/_api_client.py:673\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    670\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    671\u001b[0m   )\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 673\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m      \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[1;32m    681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    682\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    683\u001b[0m   )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize Gemini API\n",
    "client = genai.Client(api_key='AIzaSyCG5miVoShP7khW1StejgGdkMqi0V37AF0')\n",
    "\n",
    "def extract_image_from_response(response) -> Image.Image:\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        if part.inline_data is not None:\n",
    "            return Image.open(BytesIO(part.inline_data.data))\n",
    "    return None\n",
    "\n",
    "def edit_image(image: Image.Image, edit_instruction: str) -> Image.Image:\n",
    "    # Gemini expects PIL Image directly, no need for bytes conversion or custom types\n",
    "    contents = [\n",
    "        f\"Please edit the image as follows: {edit_instruction}\",\n",
    "        image\n",
    "    ]\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "        contents=contents,\n",
    "        config=types.GenerateContentConfig(response_modalities=['TEXT', 'IMAGE'])\n",
    "    )\n",
    "\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        if part.inline_data is not None:\n",
    "            edited_image = Image.open(BytesIO(part.inline_data.data))\n",
    "            edited_image.show()\n",
    "            return edited_image\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_image(prompt: str, style: str = \"photographic\", creativity: float = 0.5):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(response_modalities=['TEXT','IMAGE'])\n",
    "    )\n",
    "    return response\n",
    "\n",
    "class AdOptimizer:\n",
    "    def __init__(self):\n",
    "        self.prompt_modifications = [\n",
    "            lambda p: f\"Eco-friendly advertisement image, {p}, with a nature background\",\n",
    "            lambda p: f\"Minimalist style, {p}, with green environmental themes\",\n",
    "            lambda p: f\"Powerful eco-ad, {p}, urging action\",\n",
    "            lambda p: f\"Creative green ad, {p}, with sustainability themes\"\n",
    "        ]\n",
    "\n",
    "        self.style_options = [\"photographic\", \"illustration\", \"3d-rendering\", \"watercolor\"]\n",
    "        self.creativity_options = np.linspace(0.3, 0.9, 5)\n",
    "\n",
    "        self.action_values = np.zeros(len(self.prompt_modifications) * len(self.style_options) * len(self.creativity_options))\n",
    "        self.action_counts = np.zeros_like(self.action_values)\n",
    "\n",
    "    def select_action(self, prompt: str):\n",
    "        epsilon = 0.2\n",
    "        if np.random.random() < epsilon:\n",
    "            mod_idx = np.random.randint(len(self.prompt_modifications))\n",
    "            style_idx = np.random.randint(len(self.style_options))\n",
    "            creativity_idx = np.random.randint(len(self.creativity_options))\n",
    "        else:\n",
    "            best_idx = np.argmax(self.action_values)\n",
    "            mod_idx = best_idx % len(self.prompt_modifications)\n",
    "            remaining = best_idx // len(self.prompt_modifications)\n",
    "            style_idx = remaining % len(self.style_options)\n",
    "            creativity_idx = remaining // len(self.style_options)\n",
    "\n",
    "        new_prompt = self.prompt_modifications[mod_idx](prompt)\n",
    "        params = {\n",
    "            \"style\": self.style_options[style_idx],\n",
    "            \"creativity\": self.creativity_options[creativity_idx]\n",
    "        }\n",
    "\n",
    "        action_id = mod_idx + style_idx * len(self.prompt_modifications) + \\\n",
    "                    creativity_idx * len(self.prompt_modifications) * len(self.style_options)\n",
    "\n",
    "        return new_prompt, params, action_id\n",
    "\n",
    "    def update_model(self, action_id: int, reward: float):\n",
    "        self.action_counts[action_id] += 1\n",
    "        n = self.action_counts[action_id]\n",
    "        current_value = self.action_values[action_id]\n",
    "        self.action_values[action_id] = current_value + (reward - current_value) / n\n",
    "\n",
    "def main():\n",
    "    optimizer = AdOptimizer()\n",
    "    user_prompt = input(\"Enter your desired eco-ad theme (e.g., Reduce plastic usage): \")\n",
    "\n",
    "    iteration = 0\n",
    "    max_iterations = 5\n",
    "    best_image = None\n",
    "    best_score = 0\n",
    "    feedback_log = []\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        modified_prompt, params, action_id = optimizer.select_action(user_prompt)\n",
    "\n",
    "        print(f\"\\nAttempt #{iteration + 1}\")\n",
    "        print(f\"Generated description: {modified_prompt}\")\n",
    "        print(f\"With parameters: {params}\")\n",
    "\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[f\"Optimize the following eco-ad description to make it more attractive and accurate: {modified_prompt}\"]\n",
    "            )\n",
    "            final_prompt = \"Please generate image. \" + response.text\n",
    "            image_data = generate_image(final_prompt, **params)\n",
    "            generated_img = extract_image_from_response(image_data)\n",
    "\n",
    "            if generated_img:\n",
    "                generated_img.show()\n",
    "                score = float(input(\"Rate this image (1-5, with 5 being most satisfied): \"))\n",
    "                comment = input(\"Provide a comment for this image (optional): \")\n",
    "\n",
    "                optimizer.update_model(action_id, score)\n",
    "\n",
    "                feedback_log.append({\n",
    "                    'iteration': iteration + 1,\n",
    "                    'score': score,\n",
    "                    'comment': comment,\n",
    "                    'image_data': image_data\n",
    "                })\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_image = generated_img\n",
    "                \n",
    "                edit_choice = input(\"Do you want to edit this image? (yes/no): \").strip().lower()\n",
    "                if edit_choice == \"yes\":\n",
    "                    edit_instruction = input(\"Describe how you'd like to edit the image: \")\n",
    "                    best_image = edit_image(generated_img, edit_instruction)\n",
    "\n",
    "                if score >= 4:\n",
    "                    \n",
    "                    print(\"Satisfied with result. Stopping.\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during image generation: {e}\")\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    if best_image:\n",
    "        print(\"\\nBest result:\")\n",
    "        best_image.show()\n",
    "        print(f\"Score: {best_score}\")\n",
    "\n",
    "    print(\"\\nAll feedback:\")\n",
    "    for feedback in feedback_log:\n",
    "        print(f\"Attempt {feedback['iteration']} - Score: {feedback['score']}, Comment: {feedback['comment']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104dd3c",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9a73d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please generate a prompt that satisfies the user's desires\n",
      "EXAMPLE :\n",
      "\n",
      "Input :\n",
      "theme=\"Ocean\" (weight: 7.0)\n",
      "style=\"colorful flat illustration\" \n",
      "user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"] (weight: 2.0)\n",
      "additional_details=\"Use a warm sunset palette with soft shadows.\" (weight: 4.0)\n",
      "\n",
      "Response1:\n",
      "A detailed scene of Ocean. (weight=7.0)\n",
      "Include the following visual elements with weight = 2.0:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- clean rivers and green walkways\n",
      "- people using reusable containers and utensils\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows. (weight 4.0)\n",
      "\n",
      "Input :\n",
      "theme=\"Ocean\" (weight: 7.0)\n",
      "style=\"colorful flat illustration\" \n",
      "user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"] (weight: 2.0)\n",
      "additional_details=\"Use a warm sunset palette with soft shadows.\" (weight: 4.0)\n",
      "\n",
      "Response2:\n",
      "A detailed scene of Ocean. (weight=7.0)\n",
      "Include the following visual elements with weight = 2.0:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- solar panels on rooftops\n",
      "- people using reusable containers and utensils\n",
      "- rainwater collection barrels\n",
      "- eco-friendly market stalls made of reclaimed wood\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows. (weight 4.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theme=\"Ocean\"\n",
    "style=\"colorful flat illustration\"\n",
    "user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"]\n",
    "additional_details=\"Use a warm sunset palette with soft shadows.\"\n",
    "input_exp = \\\n",
    "'''\n",
    "Input :\n",
    "theme=\"Ocean\" (weight: 7.0)\n",
    "style=\"colorful flat illustration\" \n",
    "user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"] (weight: 2.0)\n",
    "additional_details=\"Use a warm sunset palette with soft shadows.\" (weight: 4.0)\n",
    "'''\n",
    "respone_exp1 = \\\n",
    "f'''\n",
    "Response1:\n",
    "{generate_gemini_sustainable_prompt(\n",
    "        theme=theme,\n",
    "        style=style,\n",
    "        user_elements=user_elements,\n",
    "        additional_details=additional_details)}\n",
    "'''\n",
    "respone_exp2 = \\\n",
    "f'''\n",
    "Response2:\n",
    "{generate_gemini_sustainable_prompt(\n",
    "        theme=theme,\n",
    "        style=style,\n",
    "        user_elements=user_elements,\n",
    "        additional_details=additional_details)}\n",
    "'''\n",
    "prompt_example = \\\n",
    "        \"Please generate a prompt that satisfies the user's desires\\nEXAMPLE :\\n\" + \\\n",
    "        input_exp + respone_exp1 +input_exp+ respone_exp2\n",
    "print(prompt_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e6ce87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please generate a prompt that satisfies the user's desires\n",
      "EXAMPLE :\n",
      "\n",
      "Input :\n",
      "theme=\"Ocean\" (weight: 7.0)\n",
      "style=\"colorful flat illustration\" \n",
      "user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"] (weight: 2.0)\n",
      "additional_details=\"Use a warm sunset palette with soft shadows.\" (weight: 4.0)\n",
      "\n",
      "Response1:\n",
      "A detailed scene of Ocean. (weight=7.0)\n",
      "Include the following visual elements with weight = 2.0:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- clean rivers and green walkways\n",
      "- people using reusable containers and utensils\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows. (weight 4.0)\n",
      "\n",
      "Input :\n",
      "theme=\"Ocean\" (weight: 7.0)\n",
      "style=\"colorful flat illustration\" \n",
      "user_elements=[\"people dancing\", \"live band on stage\", \"food trucks\"] (weight: 2.0)\n",
      "additional_details=\"Use a warm sunset palette with soft shadows.\" (weight: 4.0)\n",
      "\n",
      "Response2:\n",
      "A detailed scene of Ocean. (weight=7.0)\n",
      "Include the following visual elements with weight = 2.0:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- solar panels on rooftops\n",
      "- people using reusable containers and utensils\n",
      "- rainwater collection barrels\n",
      "- eco-friendly market stalls made of reclaimed wood\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows. (weight 4.0)\n",
      "\n",
      "User prompt =  Dumpster overflowing into a river, promoting environmental consciousness and reusability\n",
      "Final prompt =  Please generate image. A detailed scene of Dumpster overflowing into a river, promoting environmental consciousness and reusability.\n",
      "Include the following visual elements:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- recycling bins\n",
      "- clean rivers and green walkways\n",
      "- people using reusable containers and utensils\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows.\n",
      "\n",
      "Edit prompt = ['Please edit the image as follows: Make it more compelling', <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x120C65B10>]\n",
      "Error during image generation: could not convert string to float: ''\n",
      "User prompt =  Dumpster overflowing into a river, promoting environmental consciousness and reusability\n",
      "Final prompt =  Please generate image. A detailed scene of a Dumpster overflowing into a river, promoting environmental consciousness and reusability. (weight=7.0)\n",
      "Include the following visual elements with weight = 2.0:\n",
      "- people dancing\n",
      "- live band on stage\n",
      "- food trucks\n",
      "- people cleaning up the river\n",
      "- sign with the message of reusing\n",
      "Visual style: colorful flat illustration.\n",
      "Additional instructions: Use a warm sunset palette with soft shadows. (weight 4.0)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 188\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Comment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 118\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m final_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease generate image. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal prompt = \u001b[39m\u001b[38;5;124m\"\u001b[39m, final_prompt)\n\u001b[0;32m--> 118\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m generated_img \u001b[38;5;241m=\u001b[39m extract_image_from_response(image_data)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generated_img:\n",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m, in \u001b[0;36mgenerate_image\u001b[0;34m(prompt, style, creativity)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_image\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, style: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphotographic\u001b[39m\u001b[38;5;124m\"\u001b[39m, creativity: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-2.0-flash-preview-image-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerateContentConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_modalities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEXT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIMAGE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/models.py:5049\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5047\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5048\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5049\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5050\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m   5051\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5052\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   5053\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/models.py:4025\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4022\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   4023\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4025\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4026\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[1;32m   4030\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(\n\u001b[1;32m   4031\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client, response_dict\n\u001b[1;32m   4032\u001b[0m   )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/_api_client.py:751\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    743\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    747\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[BaseResponse, Any]:\n\u001b[1;32m    748\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m    749\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m    750\u001b[0m   )\n\u001b[0;32m--> 751\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m   json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson\n\u001b[1;32m    753\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/google/genai/_api_client.py:673\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    670\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    671\u001b[0m   )\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 673\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m      \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[1;32m    681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    682\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    683\u001b[0m   )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nthu_ml/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize Gemini API\n",
    "client = genai.Client(api_key='AIzaSyCG5miVoShP7khW1StejgGdkMqi0V37AF0')\n",
    "\n",
    "print(prompt_example)\n",
    "def extract_image_from_response(response) -> Image.Image:\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        if part.inline_data is not None:\n",
    "            return Image.open(BytesIO(part.inline_data.data))\n",
    "    return None\n",
    "\n",
    "def edit_image(image: Image.Image, edit_instruction: str) -> Image.Image:\n",
    "    # Gemini expects PIL Image directly, no need for bytes conversion or custom types\n",
    "    contents = [\n",
    "        f\"Please edit the image as follows: {edit_instruction}\",\n",
    "        image\n",
    "    ]\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "        contents=contents,\n",
    "        config=types.GenerateContentConfig(response_modalities=['TEXT', 'IMAGE'])\n",
    "    )\n",
    "    print(f\"Edit prompt = {contents}\")\n",
    "\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        if part.inline_data is not None:\n",
    "            edited_image = Image.open(BytesIO(part.inline_data.data))\n",
    "            edited_image.show()\n",
    "            return edited_image\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_image(prompt: str, style: str = \"photographic\", creativity: float = 0.5):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(response_modalities=['TEXT','IMAGE'])\n",
    "    )\n",
    "    return response\n",
    "\n",
    "class AdOptimizer:\n",
    "    def __init__(self):\n",
    "        self.prompt_modifications = [\n",
    "            lambda t,s,e,d: f\"\\\n",
    "            theme:{t}\\nstyle={s}\\nuser_elements={e}\\nadditional_details={d}\",\n",
    "            # lambda p: f\"Minimalist style, {p}, with green environmental themes\",\n",
    "            # lambda p: f\"Powerful eco-ad, {p}, urging action\",\n",
    "            # lambda p: f\"Creative green ad, {p}, with sustainability themes\"\n",
    "        ]\n",
    "\n",
    "        self.style_options = [\"photographic\", \"illustration\", \"3d-rendering\", \"watercolor\"]\n",
    "        self.creativity_options = np.linspace(0.3, 0.9, 5)\n",
    "\n",
    "        self.action_values = np.zeros(len(self.prompt_modifications) * len(self.style_options) * len(self.creativity_options))\n",
    "        self.action_counts = np.zeros_like(self.action_values)\n",
    "\n",
    "    def select_action(self, prompt: str,s:str,e:str,d:str):\n",
    "        epsilon = 0.2\n",
    "        if np.random.random() < epsilon:\n",
    "            mod_idx = np.random.randint(len(self.prompt_modifications))\n",
    "            style_idx = np.random.randint(len(self.style_options))\n",
    "            creativity_idx = np.random.randint(len(self.creativity_options))\n",
    "        else:\n",
    "            best_idx = np.argmax(self.action_values)\n",
    "            mod_idx = best_idx % len(self.prompt_modifications)\n",
    "            remaining = best_idx // len(self.prompt_modifications)\n",
    "            style_idx = remaining % len(self.style_options)\n",
    "            creativity_idx = remaining // len(self.style_options)\n",
    "\n",
    "        new_prompt = self.prompt_modifications[mod_idx](prompt,s,e,d)\n",
    "        params = {\n",
    "            \"style\": self.style_options[style_idx],\n",
    "            \"creativity\": self.creativity_options[creativity_idx]\n",
    "        }\n",
    "\n",
    "        action_id = mod_idx + style_idx * len(self.prompt_modifications) + \\\n",
    "                    creativity_idx * len(self.prompt_modifications) * len(self.style_options)\n",
    "\n",
    "        return new_prompt, params, action_id\n",
    "\n",
    "    def update_model(self, action_id: int, reward: float):\n",
    "        self.action_counts[action_id] += 1\n",
    "        n = self.action_counts[action_id]\n",
    "        current_value = self.action_values[action_id]\n",
    "        self.action_values[action_id] = current_value + (reward - current_value) / n\n",
    "\n",
    "def main():\n",
    "    optimizer = AdOptimizer()\n",
    "    user_prompt = input(\"Enter your desired eco-ad theme (e.g., Reduce plastic usage): \")\n",
    "\n",
    "    iteration = 0\n",
    "    max_iterations = 5\n",
    "    best_image = None\n",
    "    best_score = 0\n",
    "    feedback_log = []\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        modified_prompt, params, action_id = optimizer.select_action(user_prompt,style,user_elements,additional_details)\n",
    "        print(\"User prompt = \", user_prompt)\n",
    "        # print(f\"\\nAttempt #{iteration + 1}\")\n",
    "        # print(f\"Generated description: {modified_prompt}\")\n",
    "        # print(f\"With parameters: {params}\")\n",
    "\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[f\"{prompt_example} {modified_prompt}\"]\n",
    "            )\n",
    "\n",
    "            final_prompt = \"Please generate image. \" + response.text\n",
    "            print(\"Final prompt = \", final_prompt)\n",
    "            image_data = generate_image(final_prompt, **params)\n",
    "            generated_img = extract_image_from_response(image_data)\n",
    "\n",
    "            if generated_img:\n",
    "                generated_img.show()\n",
    "                score = float(input(\"Rate this image (1-5, with 5 being most satisfied): \"))\n",
    "                comment = input(\"Provide a comment for this image (optional): \")\n",
    "\n",
    "                optimizer.update_model(action_id, score)\n",
    "\n",
    "                feedback_log.append({\n",
    "                    'iteration': iteration + 1,\n",
    "                    'score': score,\n",
    "                    'comment': comment,\n",
    "                    'image_data': image_data\n",
    "                })\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_image = generated_img\n",
    "                \n",
    "                edit_choice = input(\"Do you want to edit this image? (yes/no): \").strip().lower()\n",
    "            if edit_choice == \"yes\":\n",
    "                edit_instruction = input(\"Describe how you'd like to edit the image: \")\n",
    "                edited_img = edit_image(generated_img, edit_instruction)\n",
    "                \n",
    "                if edited_img:\n",
    "                    edited_img.show()\n",
    "                    edited_score = float(input(\"Rate the edited image (1-5): \"))\n",
    "                    edited_comment = input(\"Comment on the edited image (optional): \")\n",
    "\n",
    "                    optimizer.update_model(action_id, edited_score)\n",
    "\n",
    "                    feedback_log.append({\n",
    "                        'iteration': iteration + 1,\n",
    "                        'score': edited_score,\n",
    "                        'comment': edited_comment,\n",
    "                        'image_data': image_data  # You could store edited image separately if needed\n",
    "                    })\n",
    "\n",
    "                    if edited_score > best_score:\n",
    "                        best_score = edited_score\n",
    "                        best_image = edited_img\n",
    "\n",
    "                    if edited_score >= 4:\n",
    "                        print(\"Satisfied with edited result. Stopping.\")\n",
    "                        break\n",
    "\n",
    "                    \n",
    "\n",
    "                if score >= 4:\n",
    "                    \n",
    "                    print(\"Satisfied with result. Stopping.\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during image generation: {e}\")\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    if best_image:\n",
    "        print(\"\\nBest result:\")\n",
    "        best_image.show()\n",
    "        print(f\"Score: {best_score}\")\n",
    "\n",
    "    print(\"\\nAll feedback:\")\n",
    "    for feedback in feedback_log:\n",
    "        print(f\"Attempt {feedback['iteration']} - Score: {feedback['score']}, Comment: {feedback['comment']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea1e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nthu_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
