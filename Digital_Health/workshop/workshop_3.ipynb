{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2chWXcuEuQN6"
   },
   "source": [
    "# Workshop 3: Let's get our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejkhuIfJDhBn"
   },
   "source": [
    "**üéØ Goals of this Workshop**\n",
    "1. Understand the best way to split the data into train and test\n",
    "2. Define the performance metrics that you are going to use in the evaluation of your model \n",
    "3. Develop a machine learning (ML) model to either:\n",
    "  - predict $SaO_2$ values -> regression\n",
    "  - predict the gap between $SaO_2$ and $SpO_2$ -> regression\n",
    "  - detect cases of Hidden Hypoxemia (HH) -> classification\n",
    "\n",
    "  The developed model can either be linear or non-linear.\n",
    "4. Implement grid-search to further optimize parameters.\n",
    "5. Assess what were the most relevant features for the regression/classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShMndyJ8DKac"
   },
   "source": [
    "**‚úèÔ∏è Expected Deliverables**\n",
    " - Developed models with the performance metrics and feature importance properly reported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eZWuEIMDL5u"
   },
   "source": [
    "**‚ùó Highlighted Pitfall(s)**\n",
    "- Outcome leakage\n",
    "- Suboptimal metrics for model evaluation\n",
    "- No improvement compared to the presented baseline / Models not learning\n",
    "- Overly complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cWtq_mGxac7"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Library imports\n",
    "2. Implement an ML pipeline with grid-search parameter tunning\n",
    "3. Model Evaluation (using meaningful metrics and assessing feature importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_aONCYOxwTe"
   },
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFhwYryFOVVT"
   },
   "source": [
    "You can add more libraries if you are familiar with them for your own model. But use these packages for the first part only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbnBPPKh7mnL"
   },
   "outputs": [],
   "source": [
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXG-Ekog8m46"
   },
   "outputs": [],
   "source": [
    "#!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvY3nMXkEAmc"
   },
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 160)\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataset Creation\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV\n",
    "\n",
    "# Dataset Processing\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Model Development\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import r2_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from yellowbrick.classifier import ClassificationReport, ClassPredictionError\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "# Feature Importance\n",
    "import shap\n",
    "\n",
    "# # For those who use Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/\"Colab Notebooks\"/\"your_path_to_drive_root_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UmjoE6gx6cz"
   },
   "source": [
    "## 2. Split dataset into train and test\n",
    "\n",
    "Before any data standardization, it is crucial to split the data into two groups, training and testing (so that there is no data leakage). To start, we will put 70% of our data into our training set, and 30% of our data into the testing set. Feel free to try other train/test splits, such as 75%/25%, or 80%/20%.\n",
    "\n",
    "You might also want to ensure that minority groups are represented in both train and test sets. For that, you can use more specific train-test-split methods, read more about it [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split). Or split according to the time someone entered the hospital (important if policies change)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr3x1ZU-IoPW"
   },
   "source": [
    "###### ‚úèÔ∏è Set your path to the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTJiwwROzFb8"
   },
   "outputs": [],
   "source": [
    "# Dataset Path:\n",
    "out_train = './train.csv'\n",
    "out_test = './test.csv'\n",
    "\n",
    "df_train = pd.read_csv(out_train)\n",
    "df_test = pd.read_csv(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpbCbDNtI0wy"
   },
   "source": [
    "###### ‚úèÔ∏è Split your labels from the remaining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8q5_Rc4dzncN"
   },
   "outputs": [],
   "source": [
    "label_cols=['hidden_hypoxemia', 'SaO2']\n",
    "\n",
    "y_train = df_train[label_cols]\n",
    "X_train = df_train.drop(columns=label_cols)\n",
    "\n",
    "y_test = df_test[label_cols]\n",
    "X_test = df_test.drop(columns=label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRA4tjY-3MQg"
   },
   "source": [
    "### Get label vectors for both possibilities: regression and classification\n",
    "\n",
    "If you want to use regression or classification, the labels used to train the model will be different. In the case of regression, you will have a numerical variables with SaO2 values, whereas in classification you need to define classes for hidden hypoxemia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUbgwdW11oXo"
   },
   "outputs": [],
   "source": [
    "y_train_c = y_train[['hidden_hypoxemia']].values\n",
    "y_test_c = y_test[['hidden_hypoxemia']].values\n",
    "y_train_r = y_train[['SaO2']].values\n",
    "y_test_r = y_test[['SaO2']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JSYCJ69x-6a"
   },
   "source": [
    "## 3. Implement ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDISqRa01ZSU"
   },
   "source": [
    "### 3.1 Naive Model Implementation\n",
    "\n",
    "What would our accuracy be if we predicted the most likely class? In this case, our prediction would simply be 1 or 0 for every patient. Using our training dataset we can create a naive model that predicts the most likely class for every patient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52rodxtie_0q",
    "outputId": "6c6d1d85-5307-41e3-df94-ceb71c54396a"
   },
   "outputs": [],
   "source": [
    "if np.sum(y_train_c == 0):\n",
    "    y_preds_cc = [1 for _ in range(len(y_test_c))]\n",
    "else:\n",
    "    y_preds_cc = [0 for _ in range(len(y_test_c))]\n",
    "\n",
    "# Check accuracy score\n",
    "accuracy_score = np.mean(y_preds_cc == y_test_c)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1C7jEOoKDZ4"
   },
   "source": [
    "###### ‚úèÔ∏è Test a naive approach to have a performance baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBtxDigXKf5o"
   },
   "outputs": [],
   "source": [
    "# Code here !\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npQLlsHc4fSV"
   },
   "source": [
    "### 3.2 Data Normalization\n",
    "\n",
    "Many machine learning models are directly influenced by the scale of the features that you input to the model. Therefore, it is important to normalize the scale of values used in your pipeline.\n",
    "\n",
    "One of the most common methods used is data standardization, but the decision should be taken considering the specific use case or model that you are developing. If you are curious, you can further read about this topic [here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdNyzisyqVBU"
   },
   "source": [
    "It is important to consider that in a dataset one might have several types of variables: categorical, continuous, binary. For both categorical and binary variables, it is not a good practice to apply standardization methods. Therefore, it is important to distinguish the different type of variables that one might have and apply normalization methods only to those that make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvmiYfpMW-t9"
   },
   "outputs": [],
   "source": [
    "feats = df_train.columns\n",
    "for feat in feats:\n",
    "    print(feat)\n",
    "    print(df_train[feat].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8gXkTFDXoF1"
   },
   "outputs": [],
   "source": [
    "binary_variables = ['invasive_vent', 'language', 'gender', 'rrt', 'mortality_in', 'HFNC', \n",
    "                    'InvasiveVent', 'NonInvasiveVent', 'None_ventilation', 'SupplementalOxygen',  'Tracheostomy', \n",
    "                    'Asian', 'Black', 'Hispanic', 'Other_race_group', 'White', \n",
    "                    'Medicaid', 'Medicare', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dTSSDqSrKha"
   },
   "outputs": [],
   "source": [
    "X_train_continuous = X_train.drop(columns=binary_variables)\n",
    "X_test_continuous = X_test.drop(columns=binary_variables)\n",
    "X_train_binary = X_train[binary_variables]\n",
    "X_test_binary = X_test[binary_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IY3nCVp5Ws1v"
   },
   "outputs": [],
   "source": [
    "preprocessor = make_pipeline(StandardScaler())\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6KZ7CHpX8Nt"
   },
   "outputs": [],
   "source": [
    "train_preprocessed = preprocessor.fit_transform(X_train_continuous)\n",
    "pd.DataFrame(train_preprocessed, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Htfy8a9-tNo1"
   },
   "outputs": [],
   "source": [
    "test_preprocessed = preprocessor.transform(X_test_continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NuWDRf1sPU2"
   },
   "source": [
    "Join the processed continuous variables with the binary ones to then feed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01xoc8ZZsO_9"
   },
   "outputs": [],
   "source": [
    "X_train_processed = pd.concat([X_train_binary, pd.DataFrame(train_preprocessed, columns=preprocessor.get_feature_names_out())], axis=1, join='inner')\n",
    "X_test_processed = pd.concat([X_test_binary, pd.DataFrame(test_preprocessed, columns=preprocessor.get_feature_names_out())], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c_7ZvUwl2ov"
   },
   "source": [
    "Note: After transforming your data, it is important to further explore it's distribution and ensure that the transformations applied make sense and resulted on what was expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ySqpkQkKi13"
   },
   "source": [
    "###### ‚úèÔ∏è Implement your own data normalization strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQkSjCneKiJj"
   },
   "outputs": [],
   "source": [
    "# (Optional)\n",
    "\n",
    "# Check your normalization, e.g. summary statistics, histograms, scatter plots, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7e8WKX33Qfr"
   },
   "source": [
    "### 3.3 Linear Regression Baseline\n",
    "\n",
    "On of the easiest Machine Learning model is **linear regression**. It assumes that the target variable can be written as a linear combination of the features.\n",
    "\n",
    "In many problems, this solution can be a very strong baseline. Thanks to its simplicity, it can be fitted very quickly even when the number of features is high. \n",
    "\n",
    "In general, wrapping together the features, preprocessing and fitting the estimator in a single pipeline makes it easier to transform, fit and predict the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFK_OGqZcGIC"
   },
   "outputs": [],
   "source": [
    "lmodel = linear_model.LinearRegression()\n",
    "\n",
    "lpipeline = make_pipeline(lmodel)\n",
    "lpipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2UCFEc91l1d"
   },
   "source": [
    "We train the model by calling the `fit` function on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tgH9TnQe_3h"
   },
   "outputs": [],
   "source": [
    "# Train the model using the training set\n",
    "lpipeline.fit(X_train_processed.values, y_train_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0q0InmHetxk"
   },
   "source": [
    "**Interpretation**: Because the linear model gives one weight to each feature, we can easily explore how it modeled our target covariate by visualizing the coefficients.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXAwleUVfjnl"
   },
   "outputs": [],
   "source": [
    "print('Examine regression coefficients:')\n",
    "linear_coefficients = pd.DataFrame(\n",
    "    lpipeline.named_steps.linearregression.coef_, columns=lpipeline[:-1].get_feature_names_out()\n",
    ")\n",
    "\n",
    "linear_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_jFEP2afiYG"
   },
   "source": [
    "‚úèÔ∏è Don't you see anything strange with some of these coefficients ? \n",
    "\n",
    "These weird coefficients are caused by multiple features measuring almost the same thing --a phenoma called multi-colinearity. Giving redundant information to a linear model, makes it predict unprecise and noisy coefficients.  \n",
    "You can learn more about [the limitations of the linear model here](https://inria.github.io/scikit-learn-mooc/python_scripts/linear_models_regularization.html).\n",
    "\n",
    "A simple solution is to force the model to avoid extreme coefficients, by adding a *regularization*. The subsequent model is called a Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX6cqnUxdvra"
   },
   "outputs": [],
   "source": [
    "# Code here !\n",
    "\n",
    "# Train the model using the training set\n",
    "ridge_model = ...\n",
    "ridge_pipeline = ...\n",
    "ridge_pipeline.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IHayT8i5kMP"
   },
   "source": [
    "Examine the regression coefficients for the Ridge estimator. It looks much more reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MThyoERe5gyz"
   },
   "outputs": [],
   "source": [
    "ridge_coefficients = pd.DataFrame(\n",
    "    {\"coefficients\": ridge_pipeline.named_steps.ridge.coef_[0], \"feature_names\": ridge_pipeline[:-1].get_feature_names_out()}\n",
    ").set_index(\"feature_names\").sort_values(\"coefficients\", ascending=False).transpose()\n",
    "\n",
    "print('Coefficients: ')\n",
    "ridge_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9kEanba58WS"
   },
   "source": [
    "We also can explore the errors of the model --called [residuals](https:/www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/residuals.html#:~:text=Definition,yi%E2%88%92%5Eyi). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXmzTK3k5iPp"
   },
   "outputs": [],
   "source": [
    "# create residual error plot\n",
    "plt.scatter(ridge_pipeline.predict(X_train_processed), ridge_pipeline.predict(X_train_processed) - y_train_r, color=\"green\", s=10, label='Train data')\n",
    "plt.scatter(ridge_pipeline.predict(X_test_processed), ridge_pipeline.predict(X_test_processed) - y_test_r, color=\"navy\", s=10, label='Test data')\n",
    "plt.hlines(y=0, xmin=0.4, xmax=1, linewidth=2, color=\"black\", linestyle=\"dotted\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"Residual errors\")\n",
    "plt.xlabel(r\"True SaO2 value: $y$\")\n",
    "plt.ylabel(r\"Error on the prediction: $\\hat y  - y$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrwiPKR26tLX"
   },
   "source": [
    "### 3.4 SVM Classification Baseline\n",
    "\n",
    "For the classification task, you might choose from a wide range of models that you think are most suitable. Here you have the example of the implementation of a Support Vector Machine (SVM).\n",
    "\n",
    "Before training the model, we need to set a given number of parameters - i.e. hyperparameters - which will be critical in building robust and accurate models. They help us find the balance between bias and variance and thus, prevent the model from overfitting or underfitting.Keep in mind that if you increase the range of hyperparameters to be tested, the training time will increase significantly. If you want more information read [here](https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeaTWpWzpOIR"
   },
   "outputs": [],
   "source": [
    "# Code here !\n",
    "\n",
    "# Defining parameter range\n",
    "param_grid = {'C': [0.1, 100], \n",
    "              'gamma': [1, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(...)\n",
    "\n",
    "# generate prediction for test dataset\n",
    "cpredictions = grid.predict(...)\n",
    "\n",
    "print('Score: {}'.format(grid.score(X_test_processed.values, y_test_c.ravel())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgcyTAk7-aiw"
   },
   "source": [
    "As you can observe, the scoring is almost 100%! Great, right? Well, let's take a closer look at the confusion matrix for a deeper analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5fOY29D-Ce9"
   },
   "outputs": [],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix(y_test_c, cpredictions))\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmugvy86-xTk"
   },
   "source": [
    "It looks like we have a really imbalanced dataset, where we have only 110 measurements with hidden hypoxia compared to 6073 normal ones. What should we do then?\n",
    "\n",
    "One can take several approaches when dealing with imbalanced datasets:\n",
    "- removing the number of datapoints for the majority class to match the number on the minority class. However, this might lead you to loose a lot of information.\n",
    "- upsample the minority class and generate synthetic data on it, using for example the SMOTE algorithm. This approach has the problem of maintaining the distribution of each variable for that class and might not provide the best results.\n",
    "- another approach might be to use an algorithm approppriate for this type of data. For that, there is a package very similar to sklearn called [Imbalanced Learn](https://imbalanced-learn.org/stable/) and add the class imbalance to the class_weight parameter in most sklearn algorithms (including in [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)). \n",
    "\n",
    "You can read more about it [here](https://medium.com/eni-digitalks/imbalanced-data-an-extensive-guide-on-how-to-deal-with-imbalanced-classification-problems-6c8df0bc2cab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PuwC89RUzuH"
   },
   "source": [
    "### 3.5 Your model\n",
    "\n",
    "Use the insigths learned from the models previously presented to build your own model with the framework you think is most suitable. You are free to use any of the code presented in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhUiMhObM-Nc"
   },
   "source": [
    "###### ‚úèÔ∏è Implement your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BP1wt2DUvJZ"
   },
   "outputs": [],
   "source": [
    "# (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft-DfvTXyVKl"
   },
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "To be able to develop an ML model for the recalibration of SpO2 levels and implement it in a clinical setting, it is crucial to properly evaluate its performance in the task that is supposed to do.\n",
    "\n",
    "A set of performance metrics should be carefully chosen, considering the clinical setting where the model will be aplied in but also the dataset where is what trained on:\n",
    "- If the dataset contains mostly one racial group, how will it perform on others patients?\n",
    "- Does the dataset have patients from a wide range of ages or is it more focused on a narrow range?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ow8GoVWd7V5m"
   },
   "source": [
    "### 4.1 Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ2o4qok9wwx"
   },
   "source": [
    "#### Regression Model\n",
    "\n",
    "Regression tasks are often evaluated using the [$R^2$ score](https://en.wikipedia.org/wiki/Coefficient_of_determination). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). In the general case when the true y is non-constant, a constant model that always predicts the average y disregarding the input features would get a $R^2$ score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sSD_kcdRVqa",
    "outputId": "f0cac84d-da8a-4f42-c3c6-98bc58d3ec38"
   },
   "outputs": [],
   "source": [
    "# Evaluate the linear model with R2 :\n",
    "y_pred_train = lpipeline.predict(X_train_processed.values)\n",
    "linear_train_r2 = r2_score(y_train_r, y_pred_train)\n",
    "print(f'Linear Regression R2 score: {linear_train_r2}')\n",
    "\n",
    "# Evaluate the ridge model with R2 :\n",
    "y_pred_train = ridge_pipeline.predict(X_train_processed.values)\n",
    "ridge_train_r2 = r2_score(y_train_r, y_pred_train)\n",
    "print(f'Ridge Regression R2 score: {ridge_train_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl--t3q8zshl"
   },
   "source": [
    "‚úèÔ∏è Different regression metrics are [implemented by sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics). Try another metric that you think is relevant to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHRUuwbu1omY"
   },
   "outputs": [],
   "source": [
    "# Code here !\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zn6uYaJ3SnuX"
   },
   "source": [
    "We saw that the regression metrics of both the linear regression and the regularized linear ridge regressions are not very satisfying. There are two explanations: either, we have not the proper variables to explain the output variables or these variables do not relate to the SaO2 with a pure linear relationship.   \n",
    "\n",
    "‚úèÔ∏è  Can you fit and evaluate a better regression model in term of $R^2$ ? Consider for example [decision trees](https://scikit-learn.org/stable/modules/tree.html#regression) or [ensemble models](https://scikit-learn.org/stable/modules/ensemble.html). But feel free to experiment with any other type of regression algorithms ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhpVmGIzSqAR"
   },
   "outputs": [],
   "source": [
    "# (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "LmNJ7wF-yWH4",
    "outputId": "a3892170-1ff2-4a87-839d-e768bc9fc730"
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(ridge_pipeline)\n",
    "visualizer.fit(X_train_processed.values, y_train_r)\n",
    "visualizer.score(X_test_processed.values, y_test_r)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "kjZ43dwJS7-I",
    "outputId": "08d0f179-30d8-4a8e-fd0c-c01f3d3cf3c0"
   },
   "outputs": [],
   "source": [
    "ridge_pipeline.fit(X_train_processed.values, y_train_r)\n",
    "hat_y_test = ridge_pipeline.predict(X_test_processed.values)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.regplot(data=None, x=y_test_r, y=hat_y_test, line_kws={\"color\":\"black\", \"linestyle\":\"dotted\"})\n",
    "plt.plot()\n",
    "ax.set(xlabel=r\"$y$\", ylabel=r\"$\\hat y$\")\n",
    "test_r2_score_ = r2_score(y_test_r, hat_y_test)\n",
    "print(f\"R2 score: {test_r2_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSc27qT5-ag7"
   },
   "source": [
    "#### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "yB7wgZUo-cVB",
    "outputId": "5f6c9d7d-90e1-4eee-edd8-3f018a1bb958"
   },
   "outputs": [],
   "source": [
    "#Instantiate the classification model and visualizer\n",
    "visualizer = ClassificationReport(SVC(), classes=[0,1], support=True)\n",
    "\n",
    "visualizer.fit(X_train_processed.values, y_train_c.ravel())        # Fit the visualizer and the model\n",
    "visualizer.score(X_test_processed.values, y_test_c.ravel())        # Evaluate the model on the test data\n",
    "visualizer.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "fvKOxNhIA3B8",
    "outputId": "8019bbb2-03c9-4068-9c18-16b285b36c23"
   },
   "outputs": [],
   "source": [
    "visualizer = ClassPredictionError(\n",
    "    SVC(), classes=[0,1])\n",
    "visualizer.fit(X_train_processed.values, y_train_c.ravel())\n",
    "visualizer.score(X_test_processed.values, y_test_c.ravel())\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agMEPLscVCmS"
   },
   "source": [
    "#### ‚úèÔ∏è Properly evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwE-jV3pVCRS"
   },
   "outputs": [],
   "source": [
    "# (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQW25qCS7ZS1"
   },
   "source": [
    "### 4.2 Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTLDuSwq72bt"
   },
   "source": [
    "Compute the SHAP(SHapley Additive exPlanations) values for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictor = lpipeline.fit(X_train, y_train_r)\n",
    "best_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "explainer = shap.Explainer(best_predictor.predict, X_train)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7dTFnT276We"
   },
   "source": [
    "Plot the SHAP values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqMC1Cdg775N"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "shap.plots.beeswarm(shap_values, max_display=10, show=False)\n",
    "plt.title(\"Feature Importance: SHAP Values for Top 10 Features\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABKV2f3X7-jZ"
   },
   "source": [
    "Plot the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aptdyExb8BPq"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "shap.plots.bar(shap_values, max_display=10, show=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4cbcdc76a7d0436193b6defc784b67fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d926e42e6dd449b9c7c80bd0b487049",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_aa0d32682dfe404aa41c5b4019ea7925",
      "value": " 0/6183 [00:00&lt;?, ?it/s]"
     }
    },
    "4dfed54effc24a269aa893e5de3b27d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d926e42e6dd449b9c7c80bd0b487049": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7328e0f997d9436dac7b624e5d0e399f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "770c958747db4657a02202fd6947bbbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7328e0f997d9436dac7b624e5d0e399f",
      "max": 6183,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99e33c81a83748dd9a1b6e2f57ede364",
      "value": 0
     }
    },
    "99e33c81a83748dd9a1b6e2f57ede364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa0d32682dfe404aa41c5b4019ea7925": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4b9d3d97c5349dd820390696dec8223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eac7657fe5994cceb700dc96212d034a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b9d3d97c5349dd820390696dec8223",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f1e087741d434f71ad48176a83cc6b3c",
      "value": "  0%"
     }
    },
    "f1e087741d434f71ad48176a83cc6b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f562e03f0d704875a3a768979033d644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eac7657fe5994cceb700dc96212d034a",
       "IPY_MODEL_770c958747db4657a02202fd6947bbbd",
       "IPY_MODEL_4cbcdc76a7d0436193b6defc784b67fc"
      ],
      "layout": "IPY_MODEL_4dfed54effc24a269aa893e5de3b27d1"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
